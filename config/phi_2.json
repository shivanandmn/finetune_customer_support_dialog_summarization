{
    "train_arguments": {
        "output_dir": "results/customer_care_dialog_summary_phi_2",
        "overwrite_output_dir": true,
        "do_train": true,
        "evaluation_strategy": "epoch",
        "per_device_train_batch_size": 4,
        "per_device_eval_batch_size": 1,
        "gradient_accumulation_steps": 2,
        "eval_accumulation_steps": 1,
        "learning_rate": 0.00005,
        "num_train_epochs": 10,
        "run_name": "customer_care_dialog_summary_phi_2",
        "load_best_model_at_end": true,
        "metric_for_best_model": "loss",
        "greater_is_better": false,
        "report_to": "tensorboard",
        "push_to_hub": true,
        "hub_model_id": "shivanandmn/customer_care_dialog_summary_phi_2",
        "push_to_hub_token": "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",
        "hub_token": "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",
        "include_tokens_per_second": true,
        "save_total_limit": 2,
        "save_strategy": "epoch",
        "hub_strategy": "end",
        "logging_strategy": "epoch",
        "lr_scheduler_type": "linear"
    },
    "model_arguments": {
        "model_name_or_path": "microsoft/phi-2",
        "cache_dir": "./cache",
        "peft_config": {
            "r": 16,
            "lora_alpha": 32,
            "lora_dropout": 0.05,
            "bias": "none",
            "target_modules": [
                "q_proj",
                "v_proj"
            ],
            "task_type": "CAUSAL_LM"
        }
    },
    "data_arguments": {
        "data_hub_path": "shivanandmn/tweet-sum-filtered",
        "prompt_template": "INSTRUCTION: Summarize this dialog:\n{dialog}\n---\nOUTPUT:"
    }
}